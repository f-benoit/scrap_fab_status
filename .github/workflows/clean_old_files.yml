name: Cleanup Old CSVs

on:
  schedule:
    - cron: "0 5 * * *"  # Every day at 05:00 UTC
  workflow_dispatch:

jobs:
  cleanup:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Delete old CSV files based on filename
        run: |
          import os
          from datetime import datetime, timedelta

          folder = "fabric_status"
          cutoff = datetime.now() - timedelta(days=7)
          deleted_files = []

          for file in os.listdir(folder):
              if file.startswith("fabric_status_") and file.endswith(".csv"):
                  try:
                      # Extract timestamp from filename
                      timestamp_str = file[len("fabric_status_"):-4]  # remove prefix and .csv
                      file_date = datetime.strptime(timestamp_str, "%Y%m%d_%H%M")

                      if file_date < cutoff:
                          os.remove(os.path.join(folder, file))
                          deleted_files.append(file)
                  except Exception as e:
                      print(f"Skipping {file} due to error: {e}")

          if deleted_files:
              print(f"Deleted {len(deleted_files)} files:")
              for f in deleted_files:
                  print(f" - {f}")
          else:
              print("No old files found.")
        shell: python

      - name: Commit and push if changes
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          CHANGES=$(git status --porcelain)

          if [ ! -z "$CHANGES" ]; then
            git add fabric_status
            git commit -m "Auto-cleanup: delete CSVs older than 7 days"
            git push
          else
            echo "No changes to commit."
          fi
